{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": "# Strong-form vs Weak-form PINN for the 1D Heat Equation\n\n## Overview\n\nThis notebook compares two formulations for solving the 1D heat equation\n$u_t = \\alpha\\, u_{xx}$ using PINNs:\n\n**Strong form** — enforces the PDE residual pointwise at collocation points:\n$$\\mathcal{L}_f = \\frac{1}{N_f}\\sum_{i=1}^{N_f}\\left(u_t^{(i)} - \\alpha\\, u_{xx}^{(i)}\\right)^2$$\n\n**Weak form** — integrates the residual against compact Gaussian test functions $\\psi_k$:\n$$\\mathcal{L}_f = \\sum_k \\left|\\langle u_t - \\alpha\\, u_{xx},\\, \\psi_k \\rangle\\right|^2$$\n\nThe weak form is more forgiving of localised residuals and can improve convergence on problems\nwhere the strong-form residual is hard to minimise pointwise.\n\n**Experiments:**\n1. Strong-form forward and inverse problems\n2. Weak-form integration method comparison (Simpson-21, GL-15, GL-25)\n3. Weak-form test function placement (uniform, random, boundary)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport numpy as np\nimport sys\nsys.path.append('..')\n\nfrom data.heat_data import HeatEquationData\nfrom models.heat_pinn_strategy import StrategicPINN, WeakFormLoss\nfrom training.trainer_strategy import StrategicPINNTrainer\nfrom utils.plotter import plot_solution\nfrom utils.test_functions import generate_compact_gaussians, plot_compact_gaussians\n\nprint('Imports successful.')"
  },
  {
   "cell_type": "markdown",
   "id": "sec-data",
   "metadata": {},
   "source": "## Data Generation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gen-data",
   "metadata": {},
   "outputs": [],
   "source": "data_gen = HeatEquationData(\n    L=1.0, T=1.0, alpha=0.01,\n    N_f=10000, N_bc=100, N_ic=200,\n    N_sensors=10, N_time_measurements=10,\n    noise_level=0.01,\n    device='cpu',\n    random_seed=42\n)\n\nbase_data = data_gen.generate_full_dataset()\ndata_gen.visualize_data(base_data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assemble-data",
   "metadata": {},
   "outputs": [],
   "source": "# Strong-form data: includes collocation points\nstrong_data = {\n    'x_f': base_data['x_f'], 't_f': base_data['t_f'],\n    'x_bc': base_data['x_bc'], 't_bc': base_data['t_bc'], 'u_bc': base_data['u_bc'],\n    'x_ic': base_data['x_ic'], 't_ic': base_data['t_ic'], 'u_ic': base_data['u_ic'],\n    'x_m': base_data['x_m'], 't_m': base_data['t_m'], 'u_m': base_data['u_m'],\n}\n\n\ndef make_weak_data(test_funcs, test_doms):\n    \"\"\"Assemble a weak-form data dict from the shared base measurements.\"\"\"\n    return {\n        'test_funcs': test_funcs,\n        'test_doms': test_doms,\n        'x_bc': base_data['x_bc'], 't_bc': base_data['t_bc'], 'u_bc': base_data['u_bc'],\n        'x_ic': base_data['x_ic'], 't_ic': base_data['t_ic'], 'u_ic': base_data['u_ic'],\n        'x_m': base_data['x_m'], 't_m': base_data['t_m'], 'u_m': base_data['u_m'],\n    }\n\n\ndef eval_inverse(model, alpha_true=0.01):\n    pred = model.get_alpha()\n    err  = abs(pred - alpha_true) / alpha_true * 100\n    print(f'True α: {alpha_true:.6f}  |  Predicted α: {pred:.6f}  |  Error: {err:.2f}%')\n    status = 'SUCCESS' if err < 5 else 'needs longer training'\n    print(f'[{status}]')"
  },
  {
   "cell_type": "markdown",
   "id": "sec-tf-intro",
   "metadata": {},
   "source": "## Test Functions for the Weak Form\n\nCompact Gaussian test functions are placed across $[0,1]^2$ to form the weak-form residual.\nEach function has support radius $r = 0.15$ and the support is clipped at the domain boundary\nso it vanishes outside its support domain.\n\nThree centre-placement strategies are available:\n\n| Placement | Description |\n|---|---|\n| `uniform` | Centres on a regular lattice — even spatial coverage |\n| `random`  | Centres sampled uniformly at random |\n| `boundary`| Centres concentrated near $x = 0$ and $x = 1$ |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tf-uniform",
   "metadata": {},
   "outputs": [],
   "source": "tf_uniform, td_uniform = generate_compact_gaussians(\n    L=1.0, T=1.0, n_funcs=50, support_radius=0.15,\n    placement='uniform', min_separation=0.05, smooth=0.0\n)\n\nweak_data_uniform = make_weak_data(tf_uniform, td_uniform)\n\nprint('Uniform placement:')\nplot_compact_gaussians(tf_uniform, td_uniform)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-strong",
   "metadata": {},
   "source": "# 1. Strong-form PINN\n\nThe strong form minimises the pointwise PDE residual at $N_f = 10\\,000$ random collocation\npoints sampled from $[0,1]^2$.  This is the original PINN formulation (Raissi et al., 2019)."
  },
  {
   "cell_type": "markdown",
   "id": "sec-strong-fwd",
   "metadata": {},
   "source": "## 1.1 Forward Problem"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-fwd",
   "metadata": {},
   "outputs": [],
   "source": "strong_fwd = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01,\n    inverse=False\n)\n\ntrainer_sf = StrategicPINNTrainer(\n    model=strong_fwd, data=strong_data,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_sf.train(epochs=5000, print_every=1000, plot_every=2500)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-fwd-plot",
   "metadata": {},
   "outputs": [],
   "source": "plot_solution(model=strong_fwd, data=strong_data, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-strong-inv",
   "metadata": {},
   "source": "## 1.2 Inverse Problem"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-inv",
   "metadata": {},
   "outputs": [],
   "source": "strong_inv = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    inverse=True,\n    alpha_init=0.02\n)\n\ntrainer_si = StrategicPINNTrainer(\n    model=strong_inv, data=strong_data,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_si.train(epochs=5000, print_every=1000, plot_every=2500)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-inv-eval",
   "metadata": {},
   "outputs": [],
   "source": "eval_inverse(strong_inv)\nplot_solution(model=strong_inv, data=strong_data, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-weak",
   "metadata": {},
   "source": "# 2. Weak-form PINN\n\nThe weak form tests the PDE residual against each test function $\\psi_k$ by integrating over\nits compact support domain $\\Omega_k$.  This avoids requiring the residual to be small at\nevery collocation point individually, which can regularise training when the solution has\nlocalised structure.\n\nIntegration is performed over $\\Omega_k$ using either\n**Simpson's rule** (uniform grid) or **Gauss–Legendre quadrature** (spectral accuracy for smooth\nintegrands)."
  },
  {
   "cell_type": "markdown",
   "id": "sec-integ-compare",
   "metadata": {},
   "source": "## 2.1 Integration Method Comparison (Forward Problem)\n\nThree integration options on the same uniform test functions:\n\n| Scheme | Points per axis | Approx. convergence order |\n|---|---|---|\n| Simpson-21 | 21 | 4th order |\n| Gauss–Legendre-15 | 15 | 28th order |\n| Gauss–Legendre-25 | 25 | 48th order |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weak-fwd-simp",
   "metadata": {},
   "outputs": [],
   "source": "weak_fwd_simp = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01, inverse=False\n)\nweak_fwd_simp.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\ntrainer_wfs = StrategicPINNTrainer(\n    model=weak_fwd_simp, data=weak_data_uniform,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_wfs.train(epochs=5000, print_every=1000, plot_every=2500)\nplot_solution(model=weak_fwd_simp, data=weak_data_uniform, alpha_true=0.01)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weak-fwd-gl15",
   "metadata": {},
   "outputs": [],
   "source": "weak_fwd_gl15 = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01, inverse=False\n)\nweak_fwd_gl15.set_loss_strategy(\n    WeakFormLoss(integration_method='gauss_legendre', n_integration_points=15)\n)\n\ntrainer_wfgl15 = StrategicPINNTrainer(\n    model=weak_fwd_gl15, data=weak_data_uniform,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_wfgl15.train(epochs=5000, print_every=1000, plot_every=2500)\nplot_solution(model=weak_fwd_gl15, data=weak_data_uniform, alpha_true=0.01)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weak-fwd-gl25",
   "metadata": {},
   "outputs": [],
   "source": "weak_fwd_gl25 = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01, inverse=False\n)\nweak_fwd_gl25.set_loss_strategy(\n    WeakFormLoss(integration_method='gauss_legendre', n_integration_points=25)\n)\n\ntrainer_wfgl25 = StrategicPINNTrainer(\n    model=weak_fwd_gl25, data=weak_data_uniform,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_wfgl25.train(epochs=5000, print_every=1000, plot_every=2500)\nplot_solution(model=weak_fwd_gl25, data=weak_data_uniform, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-weak-inv",
   "metadata": {},
   "source": "## 2.2 Inverse Problem\n\nRecover $\\alpha$ from noisy sensor measurements using the weak form.\nSimpson-21 and GL-15 are both tested."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weak-inv-simp",
   "metadata": {},
   "outputs": [],
   "source": "weak_inv_simp = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    inverse=True, alpha_init=0.02\n)\nweak_inv_simp.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\ntrainer_wis = StrategicPINNTrainer(\n    model=weak_inv_simp, data=weak_data_uniform,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_wis.train(epochs=5000, print_every=1000, plot_every=2500)\neval_inverse(weak_inv_simp)\nplot_solution(model=weak_inv_simp, data=weak_data_uniform, alpha_true=0.01)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weak-inv-gl",
   "metadata": {},
   "outputs": [],
   "source": "weak_inv_gl = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    inverse=True, alpha_init=0.02\n)\nweak_inv_gl.set_loss_strategy(\n    WeakFormLoss(integration_method='gauss_legendre', n_integration_points=15)\n)\n\ntrainer_wig = StrategicPINNTrainer(\n    model=weak_inv_gl, data=weak_data_uniform,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\ntrainer_wig.train(epochs=5000, print_every=1000, plot_every=2500)\neval_inverse(weak_inv_gl)\nplot_solution(model=weak_inv_gl, data=weak_data_uniform, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-placement",
   "metadata": {},
   "source": "# 3. Test Function Placement Experiments\n\nThe choice of test-function centres affects how the weak-form residual covers the domain.\nUniform placement gives even coverage; random placement introduces stochasticity (which can\nhelp escape local minima); boundary placement focuses capacity near the Dirichlet boundaries\nwhere the residual is often largest.\n\nAll experiments in this section use Simpson-21 integration."
  },
  {
   "cell_type": "markdown",
   "id": "sec-placement-random",
   "metadata": {},
   "source": "## 3.1 Random placement"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tf-random",
   "metadata": {},
   "outputs": [],
   "source": "tf_random, td_random = generate_compact_gaussians(\n    L=1.0, T=1.0, n_funcs=50, support_radius=0.15,\n    placement='random', min_separation=0.05, smooth=0.0\n)\n\nweak_data_random = make_weak_data(tf_random, td_random)\nplot_compact_gaussians(tf_random, td_random)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-fwd",
   "metadata": {},
   "outputs": [],
   "source": "m_rand_fwd = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01, inverse=False\n)\nm_rand_fwd.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\nt_rand_fwd = StrategicPINNTrainer(\n    model=m_rand_fwd, data=weak_data_random,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\nt_rand_fwd.train(epochs=5000, print_every=1000, plot_every=2500)\nplot_solution(model=m_rand_fwd, data=weak_data_random, alpha_true=0.01)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-inv",
   "metadata": {},
   "outputs": [],
   "source": "m_rand_inv = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    inverse=True, alpha_init=0.02\n)\nm_rand_inv.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\nt_rand_inv = StrategicPINNTrainer(\n    model=m_rand_inv, data=weak_data_random,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\nt_rand_inv.train(epochs=5000, print_every=1000, plot_every=2500)\neval_inverse(m_rand_inv)\nplot_solution(model=m_rand_inv, data=weak_data_random, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-placement-boundary",
   "metadata": {},
   "source": "## 3.2 Boundary placement"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tf-boundary",
   "metadata": {},
   "outputs": [],
   "source": "tf_boundary, td_boundary = generate_compact_gaussians(\n    L=1.0, T=1.0, n_funcs=50, support_radius=0.15,\n    placement='boundary', min_separation=0.05, smooth=0.0\n)\n\nweak_data_boundary = make_weak_data(tf_boundary, td_boundary)\nplot_compact_gaussians(tf_boundary, td_boundary)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boundary-fwd",
   "metadata": {},
   "outputs": [],
   "source": "m_bnd_fwd = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    alpha_true=0.01, inverse=False\n)\nm_bnd_fwd.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\nt_bnd_fwd = StrategicPINNTrainer(\n    model=m_bnd_fwd, data=weak_data_boundary,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\nt_bnd_fwd.train(epochs=5000, print_every=1000, plot_every=2500)\nplot_solution(model=m_bnd_fwd, data=weak_data_boundary, alpha_true=0.01)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boundary-inv",
   "metadata": {},
   "outputs": [],
   "source": "m_bnd_inv = StrategicPINN(\n    layers=[2, 50, 50, 50, 50, 1],\n    inverse=True, alpha_init=0.02\n)\nm_bnd_inv.set_loss_strategy(\n    WeakFormLoss(integration_method='simpson', n_integration_points=21)\n)\n\nt_bnd_inv = StrategicPINNTrainer(\n    model=m_bnd_inv, data=weak_data_boundary,\n    learning_rate=1e-3, switch_var=0.1, switch_slope=0.001,\n    adaptive_weights=True,\n)\n\nt_bnd_inv.train(epochs=5000, print_every=1000, plot_every=2500)\neval_inverse(m_bnd_inv)\nplot_solution(model=m_bnd_inv, data=weak_data_boundary, alpha_true=0.01)"
  },
  {
   "cell_type": "markdown",
   "id": "sec-conclusion",
   "metadata": {},
   "source": "# Conclusions\n\n## Strong form vs Weak form\n\n| Aspect | Strong form | Weak form |\n|---|---|---|\n| Residual | Pointwise at $N_f$ collocation points | Integrated against $K$ test functions |\n| PDE inputs | `x_f`, `t_f` tensors | compact Gaussian functions + domains |\n| Memory | $\\propto N_f$ | $\\propto K \\times n_q^2$ |\n| Integration | None | Simpson or Gauss–Legendre |\n| Noise sensitivity | Higher (pointwise) | Lower (averaged over support) |\n\n## Integration method\n\nAll three schemes (Simpson-21, GL-15, GL-25) converge for this smooth PDE.\nGL-15 is a good default: spectral accuracy at lower cost than GL-25.\n\n## Test function placement\n\nUniform placement is the safest default.  Random placement is competitive and can sometimes\nconverge faster.  Boundary placement is useful when the solution is hardest to fit near\n$x = 0$ or $x = 1$."
  }
 ]
}